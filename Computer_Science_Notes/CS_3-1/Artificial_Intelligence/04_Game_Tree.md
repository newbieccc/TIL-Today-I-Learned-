# # 인공지능

## 04. 게임트리

- 컴퓨터과학과 이병래 교수님

### (1) 최대최소 탐색

- 최대최소 탐색(minimax search)의 개념
    - 상대방과의 대결에서 승리하기 위한 게임
    - 최대화 및 최소화
        - 최대화 : 내 차례에서는 내가 둘 수 있는 수 중에서 나에게 가장 유리한 수를 선택함
        - 최소화 : 상대방은 자신이 둘 수 있는 수중에서 나에게 가장 불리한 수를 두려고 할 것이라고 가정함
    - 최대최소 탐색에 의한 수의 선택
        - 현재 상태를 루트노드로 하여 최대화와 최소화 단계를 반복함으로써 현재 상태에서 둘 수 있는 다음 수들의 가치를 평가한 후, 그 중 가장 유리한 수를 선택함
        - 나와 상대방이 각자에게 최적의 선택을 한다는 가정하에 나에게 최악인 선택(최소가치)을 하는 상대방을 대상으로 나의 결정의 가치가 최대가 되는 결정을 내림
    - 탐색의 진행
        - 트리의 규모가 매우 클 경우 모든 경우의 수를 탐색하여 종단상태까지 도달할 수 없음
            - 종단상태 : 더 이상 게임을 진행할 수 없는 상태
                - 승리 / 패배 / 무승부가 결정되는 상태
        - 시스템의 가용자원에 따라 얼마나 깊이 탐색 과정을 반복할 것인지를 정함
            - 정해진 깊이에 도달하면 경험적 지식을 반영하여 설계된 평가함수를 통해 그 노드의 가치를 추정
    - a-b 가지치기
        - 최대최소 탐색트리에서 탐색이 불필요한 가지를 잘라 내서 탐색의 성능을 높이기 위한 알고리즘
            - a : 어떠한 최대화 노드의 최대화 과정에서 지금까지 구한 가장 큰 가치
                - 앞으로 가치를 구하려는 후계노드(최소화 노드임)는 보다 더 큰 가치를 가져야만 그 최대화 노드의 가치가 될 수 있음
                - 최소화 노드에서 어느 후계노드의 가치가 v일 때 a>=v 라면 그 최소화 노드의 나머지 후계노드들은 가지치기함
            - b : 어떠한 최소화 노드의 최소화 과정에서 지금까지 구한 가장 작은 가치
                - 앞으로 가치를 구하려는 후계노드(최대화 노드임)는 보다 더 작은 가치를 가져야만 그 최소화 노드의 가치가 될 수 있음
                - 최대화 노드에서 어느 후계노드의 가치가 v일 때 b<=v라면 그 최대화 노드의 나머지 후계노드들은 가지치기함

### (2) 몬테카를로 트리 탐색

- 몬테카를로 트리 탐색(Monte Carlo Tree search : MCTS)
    - 게임과 같은 의사결정 문제에 활용되는 경험적 탐색 알고리즘
    - 탐색공간의 무작위 표본화를 바탕으로 탐색트리를 구성함
        - 노드 n<sub>i</sub : 게임의 특정 상태 표현
        - 활용 (exploitation)
        - 탐사 (exploration)
    - MCTS 알고리즘을 구성하는 네 단계
        - 선택
            - 루트노드에서 시작하여 선택전략에 따라 자식노드를 선택하는 과정을 깊이방향으로 반복
            - 아직 시도해 보지 않은 행동이 남아 있는 노드에 도달할 때까지 반복
        - 확장
            - 선택된 노드에 새로운 행동을 함으로써 자식노드를 생성하고 트리에 추가하여 트리를 확장
        - 시뮬레이션
            - 확장된 노트로부터 시작하여 게임이 끝날 때까지 스스로 게임을 진행 (롤아웃, 플레이아웃)
            - 모의게임의 겨로가 : 게임에 따라 정의된 점수
        - 역전파
            - 시뮬레이션 결과를 확장된 노드로부터 루트노드까지 선택경로를 따라 역전파하여 통계를 업데이트함
    - 선택 전략
        - 주어진 노드의 자식노드 중 하나를 선택하기 위한 전략
        - 탐사와 활용 사이의 균형을 이룰 수 있도록 설계
            - 활용 (exploitation)
                - 평가의 불확실성으로 인해 아직은 덜 유망한 것으로 보이지만 향후 우수한 것으로 드러날 수 있는 수들을 선택할 수 있도록 하는 것
            - 탐사 (exploration)
                - 지금까지의 결과 중 가장 우수한 결과를 이끌어 내는 수를 선택하는 것
        - UCT(upper confidence bound applied to trees) 알고리즘
            - UCB1 : 잘 알려진 신뢰도 상한(upper confidence bound : UCB)
            - 노드 n<sub>p</sub>에서 자식노드들 중 하나를 선택할 때 자식노드 n<sub>i</sub>의 UCB1의 계산
    - 시뮬레이션 전략
        - 선택된 노드로부터 게임이 끝날 때까지 스스로 수를 선택하여 게임을 진행함
        - 수의 선택 방법
            - 순수한 무작위 방법
            - 적절한 시뮬레이션 전략에 따른 유사 무작위 수
    - 역전파 전략 가치의 누적값과 방문횟수를 각각의 노드에 저장하고, 이의 평균을 사용하는 방법이 많이 쓰임
- 몬테카를로 트리탐색을 위한 전략의 결정
    - 최종적인 최적 행동 선택
        - 적절히 정한 계산 한계에 도달하여 시뮬레이션을 마치고, 최종적으로 루트에서 자식노드들 중 하나를 선택하여 다음 수를 결정하는 전략
            - 최대 자식(max child) : 가장 큰 보상을 갖는 자식을 선택
            - 강인한 자식(robust chile) : 가장 많이 방문한 자식을 선택
            - 최대-강인 자식(max-robust child) : 방문횟수가 가장 많고 가장 큰 보상을 갖는 루트 자식을 선택
            - 안전한 자식(secure child) : 신뢰도 하한(lower confidence bound)이 최대인 자식을 선택
- Alphago Fan 개요
    - 몬테카를로 트리 탐색을 수행함
    - 탐색의 각 단계에 필요한 결정을 하기 위해 프로 기사 대국의 기보와 자가대결을 통해 학습된 신경망을 활용
        - 바둑판의 돌의 배치를 19x19영상의 형태로 전달하고, 이를 CNN으로 학습, 분류, 회귀 등의 처리를 함
        - 가치망을 이요하여 착점의 가치를 평가하고 정책망을 이용하여 착점을 샘플리하거나 탐색 진행 방향 결정
    - AlphaGo Lee, AlphaGo Master, AlphaGo Zero 등
